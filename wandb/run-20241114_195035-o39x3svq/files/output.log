# Positive Proposals:27
# Negative Proposals:469
# Positive Proposals:24
# Negative Proposals:349
# Positive Proposals:22
# Negative Proposals:426
Base_Network(
  (beginning): Sequential(
    (0): Conv2d(3, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.2, inplace=False)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (convolutional): Sequential(
    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.2, inplace=False)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): ReLU()
    (8): Dropout(p=0.2, inplace=False)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU()
    (13): Dropout(p=0.2, inplace=False)
    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (15): Conv2d(32, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (16): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU()
    (18): Dropout(p=0.2, inplace=False)
    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (20): Conv2d(40, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU()
    (23): Dropout(p=0.2, inplace=False)
    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fully_connected): Sequential(
    (0): Linear(in_features=192, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.2, inplace=False)
    (3): Linear(in_features=512, out_features=1, bias=True)
  )
)
Epoch 1/300: Train Loss: 0.405, Val Loss: 0.985, Train Acc: 81.25%, Val Acc: 45.58%, Test Acc: 48.44%
Epoch 2/300: Train Loss: 0.243, Val Loss: 1.175, Train Acc: 89.11%, Val Acc: 46.92%, Test Acc: 57.14%
Epoch 3/300: Train Loss: 0.113, Val Loss: 1.405, Train Acc: 96.98%, Val Acc: 50.67%, Test Acc: 49.55%
Epoch 4/300: Train Loss: 0.054, Val Loss: 1.385, Train Acc: 98.19%, Val Acc: 56.30%, Test Acc: 64.73%
Epoch 5/300: Train Loss: 0.072, Val Loss: 1.108, Train Acc: 97.58%, Val Acc: 59.79%, Test Acc: 62.05%
Epoch 6/300: Train Loss: 0.045, Val Loss: 1.589, Train Acc: 98.79%, Val Acc: 59.79%, Test Acc: 51.12%
Epoch 7/300: Train Loss: 0.027, Val Loss: 1.919, Train Acc: 99.40%, Val Acc: 57.91%, Test Acc: 52.23%
Epoch 8/300: Train Loss: 0.042, Val Loss: 2.920, Train Acc: 98.59%, Val Acc: 49.06%, Test Acc: 51.12%
Epoch 9/300: Train Loss: 0.015, Val Loss: 2.094, Train Acc: 99.60%, Val Acc: 52.01%, Test Acc: 52.68%
Epoch 10/300: Train Loss: 0.011, Val Loss: 2.104, Train Acc: 99.60%, Val Acc: 56.30%, Test Acc: 54.69%
[34m[1mwandb[0m: Ctrl + C detected. Stopping sweep.
