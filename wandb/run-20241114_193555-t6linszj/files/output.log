# Positive Proposals:27
# Negative Proposals:469
# Positive Proposals:24
# Negative Proposals:349
# Positive Proposals:22
# Negative Proposals:426
Base_Network(
  (beginning): Sequential(
    (0): Conv2d(3, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.2, inplace=False)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (convolutional): Sequential(
    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.2, inplace=False)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): ReLU()
    (8): Dropout(p=0.2, inplace=False)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(24, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU()
    (13): Dropout(p=0.2, inplace=False)
    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (15): Conv2d(32, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (16): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (17): ReLU()
    (18): Dropout(p=0.2, inplace=False)
    (19): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (20): Conv2d(40, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU()
    (23): Dropout(p=0.2, inplace=False)
    (24): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (fully_connected): Sequential(
    (0): Linear(in_features=192, out_features=512, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.2, inplace=False)
    (3): Linear(in_features=512, out_features=1, bias=True)
    (4): Sigmoid()
  )
)
Epoch 1/300: Train Loss: 0.606, Val Loss: 0.692, Train Acc: 50.40%, Val Acc: 54.42%, Test Acc: 51.56%
Epoch 2/300: Train Loss: 0.571, Val Loss: 0.671, Train Acc: 47.58%, Val Acc: 53.08%, Test Acc: 46.88%
Epoch 3/300: Train Loss: 0.531, Val Loss: 0.687, Train Acc: 53.83%, Val Acc: 51.74%, Test Acc: 50.45%
Epoch 4/300: Train Loss: 0.552, Val Loss: 0.679, Train Acc: 51.81%, Val Acc: 52.55%, Test Acc: 47.32%
Epoch 5/300: Train Loss: 0.531, Val Loss: 0.653, Train Acc: 53.23%, Val Acc: 52.01%, Test Acc: 50.22%
Epoch 6/300: Train Loss: 0.546, Val Loss: 0.690, Train Acc: 50.60%, Val Acc: 49.87%, Test Acc: 51.56%
Epoch 7/300: Train Loss: 0.539, Val Loss: 0.659, Train Acc: 49.60%, Val Acc: 47.18%, Test Acc: 47.77%
Epoch 8/300: Train Loss: 0.527, Val Loss: 0.676, Train Acc: 48.99%, Val Acc: 52.28%, Test Acc: 48.88%
Epoch 9/300: Train Loss: 0.526, Val Loss: 0.689, Train Acc: 50.00%, Val Acc: 52.55%, Test Acc: 49.55%
[34m[1mwandb[0m: Ctrl + C detected. Stopping sweep.
